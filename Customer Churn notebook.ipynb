{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Customer Churn Prediction\nThis is a sample Jupyter notebook to illustrate how to leverage SparkML in training an ML model for predicting customer churn.\n\n**Please confirm the environment for this notebook is Python 3.5 with Spark**.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Install PySpark\nIf you are using an environment which includes Spark, you do NOT need to explicitly install the pyspark libraries like we're doing here. However, if you are using a vanilla Python 3.5 environment, then you need to execute the following step to install PySpark."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting pyspark==2.1.3\n  Downloading https://files.pythonhosted.org/packages/bd/e4/00786837b5f61c0d7ff7f75b116f1c6595f833f3984c25c1da7dbce36cc0/pyspark-2.1.3.tar.gz (181.3MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 181.3MB 5.5kB/s eta 0:00:01\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 136.4MB 60.1MB/s eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.7 (from pyspark==2.1.3)\n  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 204kB 5.0MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Running setup.py bdist_wheel for pyspark ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/0a/ac/b0/5b8145c9aeb42e735e5796b6539ffee1a17eb5aa9202a007b2\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.1.3\n"
                }
            ],
            "source": "!pip install pyspark==2.1.3"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Load Modules\nIn the next cell, we import a number of modules that will be used in subsequent cells in this notebook."
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": "import os\nimport urllib\nimport pandas as pd"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The Dataset\n\nA sample dataset we will be using for predicting customer churn. It includes information about:  \n- Customers who left within the last month \u2013 the column is called Churn\n\n- Services that each customer has signed up for \u2013 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n\n- Customer account information \u2013 how long they\u2019ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n\n- Demographic info about customers \u2013 gender, age range, and if they have partners and dependents\n\nLink for getting the dataset: [https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv](https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2. Loading Our Dataset\n\nThere are different methods to load the dataset. In the next cell, we use a simple method by downloading the dataset from the web using urllib and then reading it into a Pandas data frame."
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": "# Download objects from a URL \ndef download_file_from_url(file_url,save_directory=None):\n    # If save directory provided then don't delete local downloads\n    working_directory = \"temp_cos_files\"\n    if save_directory is not None:\n        working_directory = save_directory\n    os.makedirs(working_directory, exist_ok=True)\n\n    file_name = os.path.basename(file_url)\n    # Sometime url include parms and need to split those off to get valid file_name\n    file_name = file_name.split('?')[0]\n    # Delete file if present as perhaps download failed and file corrupted\n    file_path = os.path.join(working_directory, file_name)\n    if os.path.exists(file_path):\n        os.remove(file_path)\n\n    file_path, _ = urllib.request.urlretrieve(file_url, file_path)\n    stat_info = os.stat(file_path)\n    print('Downloaded', file_path, stat_info.st_size, 'bytes.')\n    return file_path"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Downloaded temp_cos_files/WA_Fn-UseC_-Telco-Customer-Churn.csv 977501 bytes.\n"
                }
            ],
            "source": "file_url = \"https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\nfile_path = download_file_from_url(file_url)"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerID</th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>MultipleLines</th>\n      <th>InternetService</th>\n      <th>OnlineSecurity</th>\n      <th>...</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>StreamingTV</th>\n      <th>StreamingMovies</th>\n      <th>Contract</th>\n      <th>PaperlessBilling</th>\n      <th>PaymentMethod</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7590-VHVEG</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>1</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5575-GNVDE</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>34</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Mailed check</td>\n      <td>56.95</td>\n      <td>1889.5</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3668-QPYBK</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Mailed check</td>\n      <td>53.85</td>\n      <td>108.15</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7795-CFOCW</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>45</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Bank transfer (automatic)</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9237-HQITU</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>70.70</td>\n      <td>151.65</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>",
                        "text/plain": "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n0  7590-VHVEG  Female              0     Yes         No       1           No   \n1  5575-GNVDE    Male              0      No         No      34          Yes   \n2  3668-QPYBK    Male              0      No         No       2          Yes   \n3  7795-CFOCW    Male              0      No         No      45           No   \n4  9237-HQITU  Female              0      No         No       2          Yes   \n\n      MultipleLines InternetService OnlineSecurity  ...  DeviceProtection  \\\n0  No phone service             DSL             No  ...                No   \n1                No             DSL            Yes  ...               Yes   \n2                No             DSL            Yes  ...                No   \n3  No phone service             DSL            Yes  ...               Yes   \n4                No     Fiber optic             No  ...                No   \n\n  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n0          No          No              No  Month-to-month              Yes   \n1          No          No              No        One year               No   \n2          No          No              No  Month-to-month              Yes   \n3         Yes          No              No        One year               No   \n4          No          No              No  Month-to-month              Yes   \n\n               PaymentMethod MonthlyCharges  TotalCharges Churn  \n0           Electronic check          29.85         29.85    No  \n1               Mailed check          56.95        1889.5    No  \n2               Mailed check          53.85        108.15   Yes  \n3  Bank transfer (automatic)          42.30       1840.75    No  \n4           Electronic check          70.70        151.65   Yes  \n\n[5 rows x 21 columns]"
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Read into a pandas dataframe\ndf_data_1 = pd.read_csv(file_path)\ndf_data_1.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Spark\nIn the next cell, we start a Spark session and read the Pandas dataframe into a Spark dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": "# Start a Spark session\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'2.1.3'"
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Verify the Spark version\nspark.version"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": "# Parse the Pandas dataframe into a Spark dataframe\ncustomer_data = spark.createDataFrame(df_data_1)"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "root\n |-- customerID: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- SeniorCitizen: long (nullable = true)\n |-- Partner: string (nullable = true)\n |-- Dependents: string (nullable = true)\n |-- tenure: long (nullable = true)\n |-- PhoneService: string (nullable = true)\n |-- MultipleLines: string (nullable = true)\n |-- InternetService: string (nullable = true)\n |-- OnlineSecurity: string (nullable = true)\n |-- OnlineBackup: string (nullable = true)\n |-- DeviceProtection: string (nullable = true)\n |-- TechSupport: string (nullable = true)\n |-- StreamingTV: string (nullable = true)\n |-- StreamingMovies: string (nullable = true)\n |-- Contract: string (nullable = true)\n |-- PaperlessBilling: string (nullable = true)\n |-- PaymentMethod: string (nullable = true)\n |-- MonthlyCharges: double (nullable = true)\n |-- TotalCharges: string (nullable = true)\n |-- Churn: string (nullable = true)\n\n"
                }
            ],
            "source": "# Verify the schema for the data\ncustomer_data.printSchema()"
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [],
            "source": "# Drop customerID field as it is not needed\ncustomer_data = customer_data.drop('customerID')"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": "# Cast the TotalCharges column to double\nfrom pyspark.sql.functions import col\n\ncustomer_data = customer_data.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"double\"))"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": "# gender        SeniorCitizen  Partner     Dependents  tenure     PhoneService  MultipleLines  InternetService  OnlineSecurity   OnlineBackup   DeviceProtection   TechSupport   StreamingTV\n#[  2.587e-01   1.344e+02      8.241e+01   1.330e+02   1.628e+04  9.726e-02     9.747e+00      9.821e+00        5.516e+02        2.301e+02      1.913e+02          5.233e+02     7.490e+00   \n\n# StreamingMovies   Contract    PaperlessBilling   PaymentMethod    MonthlyCharges    TotalCharges\n# 8.235e+00         1.116e+03   1.057e+02          5.849e+01        7.945e+04         4.572e+05]\n\n# Best features seem to be TotalCharges (or MonthlyCharges), tenure, Contract, OnlineSecurity, TechSupport\n# Can possibly also include OnlineBackup, DeviceProtection, Dependents, and SeniorCitizen\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Spark Pipeline\nIn the next cell we define the Spark Pipeline which outlines the operations to execute on the data set to train ML model.\nSpecifically, the pipeline consists of the following steps:\n\n- Map the output Churn column to an index label (0/1)\n- Map any input columns that would be used for training into index labels\n- Assemble the features to be used for training into a FEATURES column\n- Apply ML training like RandomForestClassifier\n- Define the pipeline to include all the previous steps"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml import Pipeline\n#from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Index the output label\nlabelIndexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\").fit(customer_data)\n\n# String to Index the columns of type string\nlabelIndexerContract = StringIndexer(inputCol=\"Contract\", outputCol=\"Contract_index\").fit(customer_data)\nlabelIndexerOnlineSecurity = StringIndexer(inputCol=\"OnlineSecurity\", outputCol=\"OnlineSecurity_index\").fit(customer_data)\nlabelIndexerTechSupport = StringIndexer(inputCol=\"TechSupport\", outputCol=\"TechSupport_index\").fit(customer_data)\n\n# Identify relevant features\n# For this example, we will use two features, tenure and TotalCharges as the features to leverage when predicting churn\n# In practice, data scientists would visualize the data and run other statistical techniques as well as business intuition to identify\n# most relevant features\nfeatureColumns = [\"TotalCharges\",\"tenure\"]\n\n\n## Assemble features of interest into one column\nassemblerFeatures = VectorAssembler(inputCols = featureColumns, outputCol = \"FEATURES\")\n\n\n# Train a RandomForest model.\nrfmodel = RandomForestClassifier(labelCol=\"label\", featuresCol=\"FEATURES\", numTrees=10)\n\n# Convert indexed output label back to original label.\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedChurn\",labels=labelIndexer.labels)\n\npipeline = Pipeline(stages=[labelIndexer, labelIndexerContract, labelIndexerOnlineSecurity, labelIndexerTechSupport, assemblerFeatures, rfmodel, labelConverter])\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": "# Remove null values from dataframe\ncustomer_data = customer_data.na.drop()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Split data for Training and Testing\nTo be able to evaluate the performance of your Machine Learning model, you need to test it on a data set which is different from the data it was trained on.\n\nTo do so, we split the data into two sets, a training data set and a test data set. We then train on the training data set and test on the test data set."
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": "\ncustomer_data_train, customer_data_test = customer_data.randomSplit([0.8, 0.2])"
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": "# Train model.  This also runs the indexers.\nmodel = pipeline.fit(customer_data_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": "\n# Make predictions.\npredictions = model.transform(customer_data_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(gender='Female', SeniorCitizen=0, Partner='No', Dependents='No', tenure=1, PhoneService='No', MultipleLines='No phone service', InternetService='DSL', OnlineSecurity='No', OnlineBackup='No', DeviceProtection='No', TechSupport='No', StreamingTV='No', StreamingMovies='No', Contract='Month-to-month', PaperlessBilling='No', PaymentMethod='Electronic check', MonthlyCharges=25.25, TotalCharges=25.25, Churn='No', label=0.0, Contract_index=0.0, OnlineSecurity_index=0.0, TechSupport_index=0.0, FEATURES=DenseVector([25.25, 1.0]), rawPrediction=DenseVector([6.0101, 3.9899]), probability=DenseVector([0.601, 0.399]), prediction=0.0, predictedChurn='No'),\n Row(gender='Female', SeniorCitizen=0, Partner='No', Dependents='No', tenure=1, PhoneService='Yes', MultipleLines='No', InternetService='DSL', OnlineSecurity='No', OnlineBackup='No', DeviceProtection='No', TechSupport='No', StreamingTV='No', StreamingMovies='No', Contract='Month-to-month', PaperlessBilling='No', PaymentMethod='Electronic check', MonthlyCharges=45.15, TotalCharges=45.15, Churn='Yes', label=1.0, Contract_index=0.0, OnlineSecurity_index=0.0, TechSupport_index=0.0, FEATURES=DenseVector([45.15, 1.0]), rawPrediction=DenseVector([4.483, 5.517]), probability=DenseVector([0.4483, 0.5517]), prediction=1.0, predictedChurn='Yes'),\n Row(gender='Female', SeniorCitizen=0, Partner='No', Dependents='No', tenure=1, PhoneService='Yes', MultipleLines='No', InternetService='DSL', OnlineSecurity='No', OnlineBackup='No', DeviceProtection='No', TechSupport='No', StreamingTV='No', StreamingMovies='No', Contract='Month-to-month', PaperlessBilling='No', PaymentMethod='Mailed check', MonthlyCharges=45.95, TotalCharges=45.95, Churn='Yes', label=1.0, Contract_index=0.0, OnlineSecurity_index=0.0, TechSupport_index=0.0, FEATURES=DenseVector([45.95, 1.0]), rawPrediction=DenseVector([4.483, 5.517]), probability=DenseVector([0.4483, 0.5517]), prediction=1.0, predictedChurn='Yes'),\n Row(gender='Female', SeniorCitizen=0, Partner='No', Dependents='No', tenure=1, PhoneService='Yes', MultipleLines='No', InternetService='DSL', OnlineSecurity='No', OnlineBackup='No', DeviceProtection='No', TechSupport='No', StreamingTV='No', StreamingMovies='Yes', Contract='Month-to-month', PaperlessBilling='Yes', PaymentMethod='Electronic check', MonthlyCharges=55.45, TotalCharges=55.45, Churn='No', label=0.0, Contract_index=0.0, OnlineSecurity_index=0.0, TechSupport_index=0.0, FEATURES=DenseVector([55.45, 1.0]), rawPrediction=DenseVector([4.483, 5.517]), probability=DenseVector([0.4483, 0.5517]), prediction=1.0, predictedChurn='Yes')]"
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "predictions.head(4)"
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+----------+-----+-----------+\n|prediction|label|   FEATURES|\n+----------+-----+-----------+\n|       0.0|  0.0|[25.25,1.0]|\n|       1.0|  1.0|[45.15,1.0]|\n|       1.0|  1.0|[45.95,1.0]|\n|       1.0|  0.0|[55.45,1.0]|\n|       1.0|  0.0| [49.9,1.0]|\n+----------+-----+-----------+\nonly showing top 5 rows\n\nTest Error = 0.224897\nAccuracy of trained ML model:  77.51031636863824\n"
                }
            ],
            "source": "## Evaluate model\n# Select example rows to display.\npredictions.select(\"prediction\", \"label\", \"FEATURES\").show(5)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\nprint(\"Accuracy of trained ML model: \", 100*accuracy)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Deploy to Watson Machine Learning"
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement not upgraded as not directly required: watson-machine-learning-client in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages\nRequirement not upgraded as not directly required: pandas in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: certifi in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: requests in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: urllib3 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: ibm-cos-sdk in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: tqdm in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: lomond in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: tabulate in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: python-dateutil>=2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement not upgraded as not directly required: pytz>=2011k in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement not upgraded as not directly required: numpy>=1.9.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\nRequirement not upgraded as not directly required: idna<2.7,>=2.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\nRequirement not upgraded as not directly required: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\nRequirement not upgraded as not directly required: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\nRequirement not upgraded as not directly required: six>=1.10.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from lomond->watson-machine-learning-client)\nRequirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\nRequirement not upgraded as not directly required: docutils>=0.10 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n"
                }
            ],
            "source": "!pip install watson-machine-learning-client"
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [],
            "source": "# Create API client\n\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\n\nclient = WatsonMachineLearningAPIClient(wml_creds)"
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": "# Publish model in Watson Machine Learning repository on Cloud\n\nmodel_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"Leigh W\", \n               client.repository.ModelMetaNames.NAME: \"Customer Churn Spark ML January 2019\"\n               }\nmodel_details = client.repository.store_model(model=model, pipeline = pipeline, meta_props=model_props, training_data=customer_data_train)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": "model_uid = client.repository.get_model_uid(model_details)"
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "------------------------------------  ------------------------------------  ------------------------  ---------\nGUID                                  NAME                                  CREATED                   FRAMEWORK\n6ab8c74d-af1d-4355-832e-7d54cf5a9a2d  Customer Churn Spark ML January 2019  2019-02-11T21:17:35.876Z  mllib-2.1\n276b744f-7523-4375-a7a3-2eab1b88e24a  Customer Churn Spark ML January 2019  2019-02-11T20:16:45.014Z  mllib-2.1\n------------------------------------  ------------------------------------  ------------------------  ---------\n"
                }
            ],
            "source": "client.repository.list_models()"
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '6ab8c74d-af1d-4355-832e-7d54cf5a9a2d' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='25e89c61-d209-460a-8b62-425d99307d0f'\n------------------------------------------------------------------------------------------------\n\n\n"
                }
            ],
            "source": "# Create the deployment.\ndeployment_details = client.deployments.create(model_uid, 'RF Predict Churn SparkML Jan2019')"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "------------------------------------  --------------------------------  ------  --------------  ------------------------  ---------  -------------\nGUID                                  NAME                              TYPE    STATE           CREATED                   FRAMEWORK  ARTIFACT TYPE\n25e89c61-d209-460a-8b62-425d99307d0f  RF Predict Churn SparkML Jan2019  online  DEPLOY_SUCCESS  2019-02-11T21:18:12.544Z  mllib-2.1  model\n095f70bf-a1fc-45b0-abdf-e0b57ccff0ea  RF Predict Churn SparkML Jan2019  online  DEPLOY_SUCCESS  2019-02-11T20:17:05.421Z  mllib-2.1  model\n------------------------------------  --------------------------------  ------  --------------  ------------------------  ---------  -------------\n"
                }
            ],
            "source": "# List the deployments.\nclient.deployments.list()"
        },
        {
            "cell_type": "raw",
            "metadata": {},
            "source": "# Optional step in case you just want to check the deployment details without running a new deployment\ndeployment_id = '06ae8db1-ce02-4184-8aa5-7cc974cddbee'\ndetails = client.deployments.get_details(deployment_id)\nprint(details)"
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'entity': {'deployable_asset': {'guid': '6ab8c74d-af1d-4355-832e-7d54cf5a9a2d', 'type': 'model', 'url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/bf9fe25f-653f-4398-b8c6-de0d7fe00656/published_models/6ab8c74d-af1d-4355-832e-7d54cf5a9a2d', 'created_at': '2019-02-11T21:18:12.518Z', 'name': 'Customer Churn Spark ML January 2019'}, 'runtime_environment': 'spark-2.1', 'scoring_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/bf9fe25f-653f-4398-b8c6-de0d7fe00656/deployments/25e89c61-d209-460a-8b62-425d99307d0f/online', 'type': 'online', 'description': 'Description of deployment', 'status_details': {'status': 'DEPLOY_SUCCESS'}, 'status': 'DEPLOY_SUCCESS', 'model_type': 'mllib-2.1', 'deployed_version': {'guid': '16a87fd1-b439-4353-b520-1c0419b6c4bd', 'url': 'https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/6ab8c74d-af1d-4355-832e-7d54cf5a9a2d/versions/16a87fd1-b439-4353-b520-1c0419b6c4bd'}, 'name': 'RF Predict Churn SparkML Jan2019'}, 'metadata': {'guid': '25e89c61-d209-460a-8b62-425d99307d0f', 'modified_at': '2019-02-11T21:18:12.719Z', 'url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/bf9fe25f-653f-4398-b8c6-de0d7fe00656/deployments/25e89c61-d209-460a-8b62-425d99307d0f', 'created_at': '2019-02-11T21:18:12.544Z'}}\n"
                }
            ],
            "source": "details = deployment_details\nprint(deployment_details)"
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/bf9fe25f-653f-4398-b8c6-de0d7fe00656/deployments/25e89c61-d209-460a-8b62-425d99307d0f/online\n"
                }
            ],
            "source": "# Extract endpoint url and display it.\n#scoring_url = client.deployments.get_scoring_url(deployment_details_RF)\nscoring_url = client.deployments.get_scoring_url(details)\nprint(scoring_url)"
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(gender='Female', SeniorCitizen=0, Partner='No', Dependents='No', tenure=1, PhoneService='No', MultipleLines='No phone service', InternetService='DSL', OnlineSecurity='No', OnlineBackup='No', DeviceProtection='No', TechSupport='No', StreamingTV='No', StreamingMovies='No', Contract='Month-to-month', PaperlessBilling='No', PaymentMethod='Electronic check', MonthlyCharges=25.25, TotalCharges=25.25, Churn='No'),\n Row(gender='Female', SeniorCitizen=0, Partner='No', Dependents='No', tenure=1, PhoneService='Yes', MultipleLines='No', InternetService='DSL', OnlineSecurity='No', OnlineBackup='No', DeviceProtection='No', TechSupport='No', StreamingTV='No', StreamingMovies='No', Contract='Month-to-month', PaperlessBilling='No', PaymentMethod='Electronic check', MonthlyCharges=45.15, TotalCharges=45.15, Churn='Yes')]"
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "customer_data_test.head(2)"
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [],
            "source": "\ntest1 = [1,25.1]\ntest2 = [1,35.75]"
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [],
            "source": "payload_scoring = {\"fields\": [\"tenure\", \"TotalCharges\"], \"values\": [test1, test2]}\n"
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'values': [[1, 25.1, [25.1, 1.0], [6.0101206538668155, 3.9898793461331854], [0.6010120653866815, 0.39898793461331855], 0.0, 'No'], [1, 35.75, [35.75, 1.0], [4.4829856796476655, 5.5170143203523345], [0.4482985679647665, 0.5517014320352335], 1.0, 'Yes']], 'fields': ['tenure', 'TotalCharges', 'FEATURES', 'rawPrediction', 'probability', 'prediction', 'predictedChurn']}\n"
                }
            ],
            "source": "# Perform prediction and display the result.\nresponse_scoring = client.deployments.score(scoring_url, payload_scoring)\nprint(response_scoring)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.5.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}